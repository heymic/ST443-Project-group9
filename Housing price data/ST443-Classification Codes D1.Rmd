---
title: "Classifer"
output: pdf_document
---

#Classification

```{r}
mean(train_df$SalePrice)
```

```{r}
train_df$Classifier <- ifelse(train_df$SalePrice <= 12.024,"Low","High")
train_df$Classifier <- as.factor(train_df$Classifier)
train_df$Classifier <- factor(train_df$Classifier, levels = c("Low", "High"))
train_df$isTrain <- NULL
```

Splitting of data into training and test set

```{r}
attach(train_df)
training<- sample(1:nrow(train_df), 1460*0.5)
test.train_df <- train_df[-training,]
train.train_df <- train_df[training,]
Classifier.test <- test.train_df$Classifier
```

#Ridge

```{r}
library(glmnet)
x <- model.matrix(Classifier~.-SalePrice, data=train.train_df)
y <- train.train_df$Classifier
x.test <- model.matrix(Classifier~.-SalePrice, data=test.train_df)
```


```{r}
fit.ridge <- glmnet(x,y,alpha=0, family="binomial")
plot(fit.ridge, xvar='lambda', lanel=TRUE)
plot(fit.ridge, xvar='dev', lanel=TRUE)
cv.ridge <- cv.glmnet(x,y,alpha=0,family="binomial")
plot(cv.ridge)
```

Ridge-Minimum Lambda

```{r}
ridge.min.lambda=cv.ridge$lambda.min
fit.ridge.min <- glmnet(x,y,alpha=0, family="binomial", lambda=ridge.min.lambda)
prediction_ridge_min_log <- predict(fit.ridge.min, x.test)
prediction_ridge_min_log_classifier <- (ifelse(prediction_ridge_min_log >0.5,1,0))
table(prediction_ridge_min_log_classifier, Classifier.test)
#mean(prediction_ridge_min_log_classifier!=Classifier.test)
```

Ridge-1se

```{r}
ridge.1se.lambda=cv.ridge$lambda.1se
fit.ridge.1se <- glmnet(x,y,alpha=0, family="binomial", lambda=ridge.1se.lambda)
prediction_ridge_1se_log <- predict(fit.ridge.1se, x.test)
prediction_ridge_1se_log_classifier <- ifelse(prediction_ridge_1se_log >0.5,1,0)
table(prediction_ridge_1se_log_classifier, Classifier.test)
#mean(prediction_ridge_1se_log_classifier!=Classifier.test)
```

#Lasso

```{r}
fit.lasso <- glmnet(x,y, family="binomial")
plot(fit.lasso, xvar='lambda', lanel=TRUE)
plot(fit.lasso, xvar='dev', lanel=TRUE)
cv.lasso <- cv.glmnet(x,y ,family="binomial")
plot(cv.lasso)
```

Lasso-Minimum Lambda

```{r}
lasso.min.lambda=cv.lasso$lambda.min
fit.lasso.min <- glmnet(x,y, family="binomial", lambda=lasso.min.lambda)
prediction_lasso_min_log <- predict(fit.lasso.min, x.test)
prediction_lasso_min_log_classifier <- (ifelse(prediction_lasso_min_log >0.5,1,0))
table(prediction_lasso_min_log_classifier, Classifier.test)
#mean(prediction_lasso_min_log_classifier!=Classifier.test)
```

Lasso-1se

```{r}
lasso.1se.lambda=cv.lasso$lambda.1se
fit.lasso.1se <- glmnet(x,y,alpha=0, family="binomial", lambda=lasso.1se.lambda)
prediction_lasso_1se_log <- predict(fit.lasso.1se, x.test)
prediction_lasso_1se_log_classifier <- ifelse(prediction_lasso_1se_log >0.5,1,0)
table(prediction_lasso_1se_log_classifier, Classifier.test)
#mean(prediction_lasso_1se_log_classifier!=Classifier.test)
```

#Classification Tree

```{r}
library(tree)
```

```{r}
tree.train_df <- tree(Classifier~.-SalePrice, train_df, subset=training)
```

```{r}
tree.pred <- predict(tree.train_df, test.train_df, type="class")
length(tree.pred)
length(Classifier.test)
table(tree.pred, Classifier.test)
mean(tree.pred!=Classifier.test)
```


```{r}
cv.train_df <- cv.tree(tree.train_df, FUN= prune.misclass)
names(cv.train_df)
cv.train_df

par(mfrow=c(1,2))
plot(cv.train_df$size, cv.train_df$dev, type="b")
plot(cv.train_df$k, cv.train_df$dev, type="b")
```

The optimal number of terminal node is 9 and we display the pruned tree graphically

```{r}
par(mfrow=c(1,1))
prune.train_df <-prune.misclass(tree.train_df, best=9)
plot(prune.train_df)
text(prune.train_df, pretty=0)
```

Compute the test error rate using the pruned tree 

```{r}
tree.pred <-predict(prune.train_df, test.train_df, type="class")
table(tree.pred,Classifier.test)
mean(tree.pred!=Classifier.test)
```

#Bagging

```{r}
library(randomForest)
```

```{r}
bag.train_df <- randomForest(Classifier~. -SalePrice, data=train.train_df, mtry=79, importance=TRUE)
bag.train_df
```

Predict

```{r}
bag_classifier <- predict(bag.train_df, newdata = test.train_df) 
table(predict=bag_classifier, truth=Classifier.test)
mean(bag_classifier!=Classifier.test)
```

#SVM

```{r}
library(e1071)
```

Basic SVM Model

```{r}
svmfit <-svm(Classifier~.-SalePrice, data=train.train_df, kernel="linear", cost=10, scale=FALSE)
print(svmfit)
svmfit$index
```

Tuning SVM Model

```{r}
tune.out <-tune(svm, Classifier~. -SalePrice , data=train.train_df, kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

We see that cost=0.01 results in the lowest cross validation error rate

tune() function stores the best model obtained, which can be assessed as follows

```{r}
bestmod <-tune.out$best.model
summary(bestmod)

svm_pred <-predict(bestmod, test.train_df)
table(predict=svm_pred, truth=Classifier.test)
mean(svm_pred!=Classifier.test)
```

#Boosting

```{r}
library(gbm)
```

```{r}
train.train_df$Classifier2 <- ifelse(train.train_df$Classifier=="High",1,0)
boost.train=gbm(Classifier2~. -SalePrice -Classifier, data=train.train_df, distribution="bernoulli", n.trees = 5000, interaction.depth = 4)
summary(boost.train)
```

Predicting

```{r}
boost_pred=predict(boost.train, newdata=test.train_df, n.trees=5000)
boost_classifier=ifelse(boost_pred >0.5,1,0)
Classifier2.test <- ifelse(Classifier.test=="High",1,0)
table(predict=boost_classifier, truth=Classifier2.test)
mean(boost_classifier!=Classifier2.test)
```