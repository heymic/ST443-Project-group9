---
title: "Classifer"
output: pdf_document
---

```{r}
library(tree)
```


```{r}
train_df <- filter(df,df$isTrain==1)
```

```{r}
median(train_df$SalePrice)
```

```{r}
train_df$Classifier <- ifelse(train_df$SalePrice >= 163000,"High","Low")
train_df$Classifier <- as.factor(train_df$Classifier)
train_df$isTrain <- NULL
```

#Classification Tree

```{r}
attach(train_df)
training<- sample(1:nrow(train_df), 1460*0.5)
test.train_df <- train_df[-training,]
train.train_df <- train_df[training,]
Classifier.test <- test.train_df$Classifier
tree.train_df <- tree(Classifier~.-SalePrice, train_df, subset=training)
```

```{r}
tree.pred <- predict(tree.train_df, test.train_df, type="class")
length(tree.pred)
length(Classifier.test)
table(tree.pred, Classifier.test)
mean(tree.pred!=Classifier.test)
```


```{r}
cv.train_df <- cv.tree(tree.train_df, FUN= prune.misclass)
names(cv.train_df)
cv.train_df

par(mfrow=c(1,2))
plot(cv.train_df$size, cv.train_df$dev, type="b")
plot(cv.train_df$k, cv.train_df$dev, type="b")
```

The optimal number of terminal node is 9 and we display the pruned tree graphically

```{r}
par(mfrow=c(1,1))
prune.train_df <-prune.misclass(tree.train_df, best=9)
plot(prune.train_df)
text(prune.train_df, pretty=0)
```
Compute the test error rate using the pruned tree 

```{r}
tree.pred <-predict(prune.train_df, test.train_df, type="class")
table(tree.pred,Classifier.test)
mean(tree.pred!=Classifier.test)
```

#Bagging

```{r}
library(randomForest)
```

```{r}
bag.train_df <- randomForest(Classifier~. -SalePrice, data=train.train_df, mtry=79, importance=TRUE)
bag.train_df
```

Predict

```{r}
bag_classifier <- predict(bag.train_df, newdata = test.train_df) 
table(predict=bag_classifier, truth=Classifier.test)
mean(bag_classifier!=Classifier.test)
```

#SVM

```{r}
library(e1071)
```

Basic SVM Model

```{r}
svmfit <-svm(Classifier~.-SalePrice, data=train.train_df, kernel="linear", cost=10, scale=FALSE)
print(svmfit)
svmfit$index
```

Tuning SVM Model

```{r}
tune.out <-tune(svm, Classifier~. -SalePrice , data=train.train_df, kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

We see that cost=0.01 results in the lowest cross validation error rate

tune() function stores the best model obtained, which can be assessed as follows

```{r}
bestmod <-tune.out$best.model
summary(bestmod)

svm_pred <-predict(bestmod, test.train_df)
table(predict=svm_pred, truth=Classifier.test)
mean(svm_pred!=Classifier.test)
```

#Boosting

```{r}
library(gbm)
```

```{r}
train.train_df$Classifier2 <- ifelse(train.train_df$Classifier=="High",1,0)
boost.train=gbm(Classifier2~. -SalePrice -Classifier, data=train.train_df, distribution="bernoulli", n.trees = 5000, interaction.depth = 4)
summary(boost.train)
```

Predicting

```{r}
boost_pred=predict(boost.train, newdata=test.train_df, n.trees=5000)
boost_classifier=ifelse(boost_pred >0.5,1,0)
Classifier2.test <- ifelse(Classifier.test=="High",1,0)
table(predict=boost_classifier, truth=Classifier2.test)
mean(boost_classifier!=Classifier2.test)
```